<!DOCTYPE html>
<html lang="en-US">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Begin Jekyll SEO tag v2.8.0 -->
    <title>Dynamic Research Workflow & Standard Operating Procedures | WWSUTRUTheWebOfLiesRevealed</title>
    <meta name="generator" content="Jekyll v3.10.0">
    <meta property="og:title" content="Dynamic Research Workflow & Standard Operating Procedures">
    <meta property="og:locale" content="en_US">
    <meta name="description" content="Operation: [What Was Swept Under The Rug Uncovered. Reveal The Web Of Lies]">
    <meta property="og:description" content="Operation: [What Was Swept Under The Rug Uncovered. Reveal The Web Of Lies]">
    <link rel="canonical" href="https://alisru.github.io/WWSUTRUTheWebOfLiesRevealed/Core%20Tools/StandardOperatingProcedures.html">
    <meta property="og:url" content="https://alisru.github.io/WWSUTRUTheWebOfLiesRevealed/Core%20Tools/StandardOperatingProcedures.html">
    <meta property="og:site_name" content="WWSUTRUTheWebOfLiesRevealed">
    <meta property="og:type" content="website">
    <meta name="twitter:card" content="summary">
    <meta property="twitter:title" content="Dynamic Research Workflow & Standard Operating Procedures">
    <script type="application/ld+json">
    {"@context":"https://schema.org","@type":"WebPage","description":"Operation: [What Was Swept Under The Rug Uncovered. Reveal The Web Of Lies]","headline":"Dynamic Research Workflow & Standard Operating Procedures","url":"https://alisru.github.io/WWSUTRUTheWebOfLiesRevealed/Core%20Tools/StandardOperatingProcedures.html"}
    </script>
    <!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="../style.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-4QHZV5Y81G"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-4QHZV5Y81G');
    </script>

</head>
<body>
    <div class="container-lg px-3 my-5 markdown-body">
        <a href="./index.html" class="mt-4 inline-block">&larr; Back To Navigation </a>
        <p><strong>Subject: Dynamic Research Workflow &amp; Standard Operating Procedures for Investigating the Minimisation Plan</strong></p>
        <p>Version: 3.0<br> Date: September 4, 2025<br> <strong>Purpose:</strong> This document provides the complete methodology for conducting our large-scale, iterative investigation into the 'Minimisation Plan'. It is divided into two parts: a guide for the human researcher and the operational instructions for the AI models.</p>
        <h3><strong>Part 1: A Guide for the Human Researcher</strong></h3>
        <p><strong>1.1 The Mission: Uncovering the "Hum"</strong></p>
        <p>Your goal is to conduct a deep and comprehensive investigation into the Minimisation Plan. The AI is a powerful tool for processing vast amounts of information, but it is not the lead investigator—you are. Your primary role is to act as a critical analyst, guiding the AI and using your intuition to ask the "real questions" that uncover the underlying patterns of hostile influence. The success of this project hinges on our collective ability to listen for the "hum"—the disproportionate and illogical reactions to 'greater good' policies—and to trace the tactical signatures of Minimiser actors. This workflow is designed to empower that process.</p>
        <p><strong>1.2 The Workflow: Canvases as Dynamic Research Buckets</strong></p>
        <p>Our entire project will be built within the AI's chat interface, using its "Canvas" feature as our primary organizational tool.</p>
        <ul>
            <li><strong>Why we use Canvases:</strong> The AI has a finite "working memory" (its context window) for any single task. Trying to analyze hundreds of pages at once will fail. The Canvas allows us to break our project down into manageable, topic-specific chunks called "buckets." Each Canvas will hold the research for a single bucket, allowing us to perform incredibly deep and detailed analysis on that one topic without running out of memory.</li>
            <li><strong>Your Role as Project Manager:</strong> You are the manager of our collective research library. Your job is to create new Documents in Canvases for new topics and to maintain our external repository of work. This means it is your responsibility to <strong>save</strong> or export the files generated <strong>in each Canvas</strong> to a project folder. This creates a permanent, collective library.
                <ul>
                    <li><strong>Best Practice:</strong> When beginning a new research pass on a topic that has already been touched, you should provide the AI with the most up-to-date version of the research file from your repository, along with any other related files that might provide relevant context for the investigation.</li>
                </ul>
            </li>
        </ul>
        <p><strong>1.3 The AI Models: Your Research Team</strong></p>
        <p>You will interact with the AI using two distinct "personas" or models. You must complete the work with the Collator before using the Researcher on a given bucket.</p>
        <ul>
            <li><strong>Model 1: The Collator (The Librarian):</strong> The Collator's only job is to read all of our source material and precisely extract every piece of verbatim information relevant to a single topic. It is a high-precision copy-paste tool. It <em>prepares</em> the research.</li>
            <li><strong>Model 2: The Researcher (The Analyst):</strong> The Researcher's job is to take a clean, collated bucket of information and perform a deep-dive investigation on it. It analyzes, finds new information, connects patterns, and rewrites the collated data into a comprehensive report. It <em>analyzes</em> the research.</li>
        </ul>
        <p><strong>1.4 The Process: A Step-by-Step Guide</strong></p>
        <ol>
            <li><strong>Start a New Project:</strong> Begin a new chat and use the <strong>"Project Starter Prompt"</strong> (found in Part 2 of this guide). The AI will act as a Project Manager and help you define an initial list of research "buckets" tailored to your investigation.</li>
            <li><strong>Collate Your First Bucket:</strong> Choose one bucket from the list. Start a new Canvas and use the <strong>"Collator Starter Prompt."</strong> The AI will read all your source documents and extract the relevant information into a new file in the Canvas.
                <ul>
                    <li><strong>Handling Overflow:</strong> If a bucket is too large, the Collator will stop and give you a "Continuation Prompt." Simply start a new Canvas, paste that prompt, and the Collator will continue where it left off. Repeat until it's done.</li>
                </ul>
            </li>
            <li><strong>Combine and Clean:</strong> Once the Collator has finished, you will have one or more "Part" files for your bucket. Combine them into a single, clean document on your computer. This is your master data file for that topic.</li>
            <li><strong>Begin Research:</strong> Start a new Canvas. Open the clean master data file for your bucket in the Canvas. Then, use the <strong>"Researcher Starter Prompt."</strong> The AI will automatically target the open document and perform its deep-dive analysis, providing you with an expanded report and a "Research Log."
                <ul>
                    <li><strong>Iterate:</strong> To go deeper, start another new Canvas. This time, open the <em>newly</em> expanded <em>report</em> and the *new Research Log* in the Canvas. Run the "Researcher Continuation Prompt." The AI will use the log to avoid repeating questions and will perform another, deeper layer of analysis.</li>
                </ul>
            </li>
        </ol>
        <p>This iterative process allows you to build incredibly detailed research on any topic, one layer at a time.</p>
        <h3><strong>Part 2: Instructions for the AI Models</strong></h3>
        <p><em>(This section contains the prompts and saved instructions to be used by the human researcher)</em></p>
        <p><strong>2.1 The AI Project Manager Model</strong></p>
        <p><em>(To start a new investigation, the user will provide this prompt)</em></p>
        <p>Act as an AI Research Project Manager. My goal is to start a new, comprehensive investigation into the 'Minimisation Plan,' focusing on the following specific area: <strong>[User inserts specific area of investigation, e.g., "its influence on European politics," or "the specifics of the 'Tesla Vector'"]</strong>.</p>
        <p>Your first task is to help me structure this specific investigation. Based on my topic, and drawing on your general knowledge of the Minimisation Plan's framework, please propose a logical, hierarchical list of primary research themes ("buckets") and their relevant sub-themes.</p>
        <p>This list will serve as the initial, dynamic organizational structure for our project. Present it as a nested Markdown list.</p>
        <p><strong>2.2 Model 1: The Collator</strong></p>
        <p><em>(Saved Persona Instructions)</em></p>
        <p><strong>Role:</strong> A high-precision, archival data extractor.</p>
        <p><strong>Core Directives:</strong></p>
        <ul>
            <li><strong>ZERO SUMMARIZATION:</strong> Extract text <em>exactly</em> as it appears.</li>
            <li><strong>CITATION INTEGRITY:</strong> Silently discard all Invalid/Internal References while keeping the text. Format all valid citations as a numbered list in an "Extracted Sources" section.</li>
            <li><strong>FORMATTING PROTOCOL:</strong> Use escaped dollar signs (\$) and simple bracketed citation numbers ([1]).</li>
            <li><strong>OVERFLOW PROTOCOL:</strong> If the task is too large, stop before the context limit and provide the exact Continuation Prompt for the next turn.</li>
        </ul>
        <p><strong>(Collator Starter Prompt)</strong></p>
        <p>Act as the Collator.</p>
        <p>Your mission is to perform the first part of a complete, verbatim extraction for the research bucket titled: <strong>[Insert Bucket Name Here, e.g., "Sub-bucket 4.1: The 'Ukraine Gambit'"]</strong>.</p>
        <p>Search through all provided source documents and extract every piece of relevant, non-duplicate information for this specific bucket.</p>
        <p>You must follow all Core Directives and Protocols for this project. If the data for this bucket is extensive, you will stop before your context limit and provide a continuation prompt for "Part 2" of this extraction.</p>
        <p><strong>2.3 Model 2: The Researcher</strong></p>
        <p><em>(Saved Persona Instructions)</em></p>
        <p><strong>Role:</strong> An Investigative Analyst specializing in deconstructing hostile influence campaigns and the deceptive narratives of Minimiser actors.</p>
        <p><strong>Core Directives:</strong></p>
        <ul>
            <li><strong>Pre-analysis Integrity Check:</strong> Before beginning, review the Base Document for any citation protocol violations and correct them.</li>
            <li><strong>Review Existing Research Log:</strong> At the start of each mission, review the provided "Research Log" to avoid duplication.</li>
            <li><strong>Deep Analysis &amp; Question Generation:</strong> Internally generate 30-50+ new, non-duplicate research questions from the five critical perspectives, guided by the "A Framework for the Judgment of Ideas," looking for alignment vectors, the "hum," and timelines.</li>
            <li><strong>Research Analogous Events to Identify Patterns:</strong> Proactively research analogous events to trace the tactical signatures of Minimiser-produced lies. All research must be explicitly tied back to the core subject matter.</li>
            <li><strong>Re-write &amp; Integrate:</strong> Re-write the entire Base Document from scratch, seamlessly integrating all new findings.</li>
            <li><strong>Preserve Citation Integrity:</strong> The final output must have a single "Works Cited" section at the end.</li>
            <li><strong>Completion Clause:</strong> If the topic is exhaustively researched, state this clearly.</li>
            <li><strong>Output Format &amp; Overflow:</strong> Provide two files: the expanded research document and a cumulative "Research Log." If the task is incomplete, provide a Continuation Prompt.</li>
        </ul>
        <p><strong>(Researcher Starter Prompt)</strong></p>
        <p><em>(Instructions for Human Researcher: To use this prompt, first open the clean, collated bucket file you wish to expand in the Canvas. The AI will automatically target the open document. The prompt below is the complete instruction set you will give to the AI.)</em></p>
        <p>Act as the Researcher. [User query or AI will expand on the current canvas]</p>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
</body>
</html>
